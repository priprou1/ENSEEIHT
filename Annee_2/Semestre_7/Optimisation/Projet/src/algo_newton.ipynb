{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1> TP-Projet d'optimisation numérique </h1>\n",
    "<h1> Algorithme de Newton </h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation \n",
    " \n",
    "1. Coder l’algorithme de Newton local en respectant la spécification ci-dessous (fichier `Algorithme_De_Newton.jl`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\paragraph{Objet}\n",
       "Cette fonction implémente l'algorithme de Newton pour résoudre un problème d'optimisation sans contraintes\n",
       "\n",
       "\\paragraph{Syntaxe}\n",
       "\\begin{verbatim}\n",
       "xmin,fmin,flag,nb_iters = Algorithme_de_Newton(f,gradf,hessf,x₀,option)\n",
       "\\end{verbatim}\n",
       "\\paragraph{Entrées :}\n",
       "\\begin{itemize}\n",
       "\\item f       : (Function) la fonction à minimiser\n",
       "\n",
       "\n",
       "\\item gradf   : (Function) le gradient de la fonction f\n",
       "\n",
       "\n",
       "\\item hessf   : (Function) la hessienne de la fonction f\n",
       "\n",
       "\n",
       "\\item x₀      : (Array\\{Float,1\\}) première approximation de la solution cherchée\n",
       "\n",
       "\n",
       "\\item options : (Array\\{Float,1\\})\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item max\\_iter      : le nombre maximal d'iterations\n",
       "\n",
       "\n",
       "\\item Tol\\_abs       : la tolérence absolue\n",
       "\n",
       "\n",
       "\\item Tol\\_rel       : la tolérence relative\n",
       "\n",
       "\n",
       "\\item ϵ             : epsilon pour les tests de stagnation\n",
       "\n",
       "\\end{itemize}\n",
       "\\end{itemize}\n",
       "\\paragraph{Sorties:}\n",
       "\\begin{itemize}\n",
       "\\item xmin    : (Array\\{Float,1\\}) une approximation de la solution du problème  : $\\min_{x \\in \\mathbb{R}^{n}} f(x)$\n",
       "\n",
       "\n",
       "\\item fmin    : (Float) $f(x_{min})$\n",
       "\n",
       "\n",
       "\\item flag    : (Integer) indique le critère sur lequel le programme s'est arrêté (en respectant cet ordre de priorité si plusieurs critères sont vérifiés)\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item 0    : CN1\n",
       "\n",
       "\n",
       "\\item 1    : stagnation du xₖ\n",
       "\n",
       "\n",
       "\\item 2    : stagnation du f\n",
       "\n",
       "\n",
       "\\item 3    : nombre maximal d'itération dépassé\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\\item nb\\_iters : (Integer) le nombre d'itérations faites par le programme\n",
       "\n",
       "\\end{itemize}\n",
       "\\paragraph{Exemple d'appel}\n",
       "\\begin{verbatim}\n",
       "f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2\n",
       "gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]\n",
       "hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]\n",
       "x₀ = [1; 0]\n",
       "options = []\n",
       "xmin,fmin,flag,nb_iters = Algorithme_De_Newton(f,gradf,hessf,x₀,options)\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "#### Objet\n",
       "\n",
       "Cette fonction implémente l'algorithme de Newton pour résoudre un problème d'optimisation sans contraintes\n",
       "\n",
       "#### Syntaxe\n",
       "\n",
       "```julia\n",
       "xmin,fmin,flag,nb_iters = Algorithme_de_Newton(f,gradf,hessf,x₀,option)\n",
       "```\n",
       "\n",
       "#### Entrées :\n",
       "\n",
       "  * f       : (Function) la fonction à minimiser\n",
       "  * gradf   : (Function) le gradient de la fonction f\n",
       "  * hessf   : (Function) la hessienne de la fonction f\n",
       "  * x₀      : (Array{Float,1}) première approximation de la solution cherchée\n",
       "  * options : (Array{Float,1})\n",
       "\n",
       "      * max_iter      : le nombre maximal d'iterations\n",
       "      * Tol_abs       : la tolérence absolue\n",
       "      * Tol_rel       : la tolérence relative\n",
       "      * ϵ             : epsilon pour les tests de stagnation\n",
       "\n",
       "#### Sorties:\n",
       "\n",
       "  * xmin    : (Array{Float,1}) une approximation de la solution du problème  : $\\min_{x \\in \\mathbb{R}^{n}} f(x)$\n",
       "  * fmin    : (Float) $f(x_{min})$\n",
       "  * flag    : (Integer) indique le critère sur lequel le programme s'est arrêté (en respectant cet ordre de priorité si plusieurs critères sont vérifiés)\n",
       "\n",
       "      * 0    : CN1\n",
       "      * 1    : stagnation du xₖ\n",
       "      * 2    : stagnation du f\n",
       "      * 3    : nombre maximal d'itération dépassé\n",
       "  * nb_iters : (Integer) le nombre d'itérations faites par le programme\n",
       "\n",
       "#### Exemple d'appel\n",
       "\n",
       "```@example\n",
       "f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2\n",
       "gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]\n",
       "hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]\n",
       "x₀ = [1; 0]\n",
       "options = []\n",
       "xmin,fmin,flag,nb_iters = Algorithme_De_Newton(f,gradf,hessf,x₀,options)\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[1m  Objet\u001b[22m\n",
       "\u001b[1m  -------\u001b[22m\n",
       "\n",
       "  Cette fonction implémente l'algorithme de Newton pour résoudre un problème\n",
       "  d'optimisation sans contraintes\n",
       "\n",
       "\u001b[1m  Syntaxe\u001b[22m\n",
       "\u001b[1m  ---------\u001b[22m\n",
       "\n",
       "\u001b[36m  xmin,fmin,flag,nb_iters = Algorithme_de_Newton(f,gradf,hessf,x₀,option)\u001b[39m\n",
       "\n",
       "\u001b[1m  Entrées :\u001b[22m\n",
       "\u001b[1m  -----------\u001b[22m\n",
       "\n",
       "    •  f : (Function) la fonction à minimiser\n",
       "\n",
       "    •  gradf : (Function) le gradient de la fonction f\n",
       "\n",
       "    •  hessf : (Function) la hessienne de la fonction f\n",
       "\n",
       "    •  x₀ : (Array{Float,1}) première approximation de la solution\n",
       "       cherchée\n",
       "\n",
       "    •  options : (Array{Float,1})\n",
       "       • max_iter : le nombre maximal d'iterations\n",
       "       • Tol_abs : la tolérence absolue\n",
       "       • Tol_rel : la tolérence relative\n",
       "       • ϵ : epsilon pour les tests de stagnation\n",
       "\n",
       "\u001b[1m  Sorties:\u001b[22m\n",
       "\u001b[1m  ----------\u001b[22m\n",
       "\n",
       "    •  xmin : (Array{Float,1}) une approximation de la solution du\n",
       "       problème : \u001b[35m\\min_{x \\in \\mathbb{R}^{n}} f(x)\u001b[39m\n",
       "\n",
       "    •  fmin : (Float) \u001b[35mf(x_{min})\u001b[39m\n",
       "\n",
       "    •  flag : (Integer) indique le critère sur lequel le programme s'est\n",
       "       arrêté (en respectant cet ordre de priorité si plusieurs critères\n",
       "       sont vérifiés)\n",
       "       • 0 : CN1\n",
       "       • 1 : stagnation du xₖ\n",
       "       • 2 : stagnation du f\n",
       "       • 3 : nombre maximal d'itération dépassé\n",
       "\n",
       "    •  nb_iters : (Integer) le nombre d'itérations faites par le\n",
       "       programme\n",
       "\n",
       "\u001b[1m  Exemple d'appel\u001b[22m\n",
       "\u001b[1m  -----------------\u001b[22m\n",
       "\n",
       "\u001b[36m  f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2\u001b[39m\n",
       "\u001b[36m  gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]\u001b[39m\n",
       "\u001b[36m  hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]\u001b[39m\n",
       "\u001b[36m  x₀ = [1; 0]\u001b[39m\n",
       "\u001b[36m  options = []\u001b[39m\n",
       "\u001b[36m  xmin,fmin,flag,nb_iters = Algorithme_De_Newton(f,gradf,hessf,x₀,options)\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using Documenter\n",
    "using Markdown  \n",
    "include(\"Algorithme_De_Newton.jl\")\n",
    "@doc Algorithme_De_Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Vérifier que les tests ci-dessous passent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : algorithme de Newton  appliqué à fct1 au point initial x011 :\u001b[22m\u001b[39m\n",
      "  * xsol = [1, 1, 1]\n",
      "  * f(xsol) = 0\n",
      "  * nb_iters = 0\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : algorithme de Newton  appliqué à fct1 au point initial x011 :\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 1.0, 0.9999999999999999]\n",
      "  * f(xsol) = 1.232595164407831e-32\n",
      "  * nb_iters = 1\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : algorithme de Newton  appliqué à fct1 au point initial x012 :\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 0.9999999999999996, 0.9999999999999987]\n",
      "  * f(xsol) = 7.296963373294359e-30\n",
      "  * nb_iters = 1\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : algorithme de Newton  appliqué à fct1 au point initial x011 :\u001b[22m\u001b[39m\n",
      "  * xsol = [1, 1, 1]\n",
      "  * f(xsol) = 0\n",
      "  * nb_iters = 0\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : algorithme de Newton  appliqué à fct2 au point initial x021 :\u001b[22m\u001b[39m\n",
      "  * xsol = [0.9999999999999999, 0.9999999999814724]\n",
      "  * f(xsol) = 3.4326461875363225e-20\n",
      "  * nb_iters = 6\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : algorithme de Newton  appliqué à fct2 au point initial x022 :\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 1.0]\n",
      "  * f(xsol) = 0.0\n",
      "  * nb_iters = 5\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : algorithme de Newton  appliqué à fct2 au point initial x023 :\u001b[22m\u001b[39m\n",
      "  * xsol = [-4.99999958629818e9, 8.673617379884035e-19]\n",
      "  * f(xsol) = 6.249997931491155e40\n",
      "  * nb_iters = 1\n",
      "  * flag = 3\n",
      "  * sol_exacte : [1, 1]\n",
      "\u001b[0m\u001b[1mTest Summary:    | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Test algo newton | \u001b[32m  22  \u001b[39m\u001b[36m   22  \u001b[39m\u001b[0m6.0s\n"
     ]
    }
   ],
   "source": [
    "using Test\n",
    "\n",
    "# Tolérance pour les tests d'égalité\n",
    "tol_erreur = sqrt(eps())\n",
    "\n",
    "## ajouter les fonctions de test\n",
    "include(\"../test/fonctions_de_tests.jl\")\n",
    "include(\"../test/tester_algo_newton.jl\")\n",
    "include(\"../src/Algorithme_De_Newton.jl\")\n",
    "\n",
    "affiche = true\n",
    "\n",
    "@testset \"Test algo newton\" begin\n",
    "\t# Tester l'algorithme de Newton\n",
    "\ttester_algo_newton(affiche,Algorithme_De_Newton)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f0 au point initial -1.5707963267948966:\u001b[22m\u001b[39m\n",
      "  * xsol = -1.5707963267948966\n",
      "  * f(xsol) = -1.0\n",
      "  * nb_iters = 0\n",
      "  * flag = 0\n",
      "  * sol_exacte : -1.5707963267948966\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f0 au point initial -1.0707963267948966:\u001b[22m\u001b[39m\n",
      "  * xsol = -1.5707963267949088\n",
      "  * f(xsol) = -1.0\n",
      "  * nb_iters = 3\n",
      "  * flag = 0\n",
      "  * sol_exacte : -1.5707963267948966\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f0 au point initial 1.5707963267948966:\u001b[22m\u001b[39m\n",
      "  * xsol = 1.5707963267948966\n",
      "  * f(xsol) = 1.0\n",
      "  * nb_iters = 0\n",
      "  * flag = 0\n",
      "  * sol_exacte : -1.5707963267948966\n"
     ]
    }
   ],
   "source": [
    "#using Pkg; Pkg.add(\"LinearAlgebra\"); Pkg.add(\"Markdown\")\n",
    "# using Documenter\n",
    "using LinearAlgebra\n",
    "using Markdown                             # Pour que les docstrings en début des fonctions ne posent\n",
    "                                           # pas de soucis. Ces docstrings sont utiles pour générer \n",
    "                                           # la documentation sous GitHub\n",
    "include(\"Algorithme_De_Newton.jl\")\n",
    "\n",
    "# Affichage les sorties de l'algorithme des Régions de confiance\n",
    "function my_afficher_resultats(algo,nom_fct,point_init,xmin,fxmin,flag,sol_exacte,nbiters)\n",
    "\tprintln(\"-------------------------------------------------------------------------\")\n",
    "\tprintstyled(\"Résultats de : \",algo, \" appliqué à \",nom_fct, \" au point initial \", point_init, \":\\n\",bold=true,color=:blue)\n",
    "\tprintln(\"  * xsol = \",xmin)\n",
    "\tprintln(\"  * f(xsol) = \",fxmin)\n",
    "\tprintln(\"  * nb_iters = \",nbiters)\n",
    "\tprintln(\"  * flag = \",flag)\n",
    "\tprintln(\"  * sol_exacte : \", sol_exacte)\n",
    "end\n",
    "\n",
    "# Fonction f0\n",
    "# -----------\n",
    "f0(x) =  sin(x)\n",
    "# la gradient de la fonction f0\n",
    "grad_f0(x) = cos(x)\n",
    "# la hessienne de la fonction f0\n",
    "hess_f0(x) = -sin(x)\n",
    "sol_exacte = -pi/2\n",
    "options = []\n",
    "\n",
    "x0 = sol_exacte\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f0,grad_f0,hess_f0,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f0\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "x0 = -pi/2+0.5\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f0,grad_f0,hess_f0,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f0\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "x0 = pi/2\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f0,grad_f0,hess_f0,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f0\",x0,xmin,f_min,flag,sol_exacte,nb_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation \n",
    "\n",
    "1. Justifier les résultats obtenus pour l'exemple $f_0$ ci-dessus;\n",
    "\n",
    "\n",
    "2. Soit \n",
    "$$ f_{1} : \\mathbb{R}^3 \\rightarrow \\mathbb{R}$$ $$ (x_1,x_2, x_3) \\mapsto  2 (x_1 +x_2 + x_3 -3)^2 + (x_1-x_2)^2 + (x_2 - x_3)^2$$ \n",
    "\n",
    "Justifier que l’algorithme implémenté converge en une itération pour $f_{1}$;\n",
    "\n",
    "3. Soit \n",
    "$$ f_{2} : \\mathbb{R}^2 \\rightarrow \\mathbb{R}$$ $$ (x_1,x_2) \\mapsto 100(x_2-x_1^2)^2 + (1-x_1)^2 $$ \n",
    "\n",
    "Justifier que l’algorithme puisse ne pas converger pour $f_{2}$ avec certains points initiaux.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réponses\n",
    "\n",
    "1. En partant de la solution exacte $x_{0} = -\\frac{\\pi}{2}$, il est logique de s'arrêter à la première itération. La CN1 est validée car le gradient de $x_0$ est nul et le gradient de $x_1$ aussi. Le flag 0 est donc celui levé.  \n",
    "\n",
    "    En partant de $x_{0} = -\\frac{\\pi}{2} + 0,5$ l'algorithme converge en 3 itérations puisque le point de départ n'est pas très loin de la solution.  \n",
    "\n",
    "    En partant de l'opposé de la solution exacte $x_{0} = \\frac{\\pi}{2}$, on termine de même après une itération, cependant on n'obtient pas le minimum. On est parti sur un maximum local donc la CN1 est aussi validée car le gradient de $x_0$ et de $x_1$ sont nuls. L'algorithme s'arrête donc avec un flag 0 aussi.  \n",
    "\n",
    "    \n",
    "\n",
    "2. L'algo de newton, utilise une linéarisation du gradient de la fonction, ici elle est déjà linéaire car $f_{1}$ est quadratique donc en une itération on converge.  \n",
    "\n",
    "3. Si une des valeurs propres de la hessienne de la fonction est nulle, elle n'est pas inversible. C'est le cas ici pour certain points. Il y aura des points où la pente de la tangente est une constante et fera qu'en effectuant l'algorithme on s'éloigne du minimum.\n",
    "\n",
    "Par exemple si on prend comme point de départ\n",
    "\n",
    "$$\n",
    "x_0 = \\begin{pmatrix} 0 \\\\ \\frac{2}{400} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "on obtient\n",
    "\n",
    "$$\n",
    "\\nabla ^2(f_2) = \\begin{pmatrix} 0 & 0 \\\\ 0 & 200 \\end{pmatrix}\n",
    "$$\n",
    "qui a donc une valeur propre égale à 0.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
